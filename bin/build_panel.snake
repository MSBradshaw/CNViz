import pandas as pd

SAMPLES_FILE = "workpanel/panel.samples"

# Load input files and options
samples_df = pd.read_csv(SAMPLES_FILE,sep='\t',header=None)
samples_df.columns = ['p_id','s_id','sex','bam','bai']

PROBESFILE = 'workpanel/Probes/probes.original.bed'

SAMPLES = samples_df['s_id']
BAM = samples_df["bam"]

for line in open('workpanel/outputdir.txt','r'):
	config['outputdir'] = line.strip()
	break

print(config)

rule all:
	input:
		expand("workpanel/Mosdepth/{sample}.per-base.bed.gz", sample=SAMPLES),
		"workpanel/Probes/probes.sorted.bed.gz",
                "workpanel/Probes/probes.sorted.bed.gz.tbi",
		expand("workpanel/ReadCounts/{sample}.num_reads.txt", sample=SAMPLES),
		"workpanel/TotalReads/total_read.txt",
		expand("workpanel/RPM/{sample}.probe.rpm_rate.bed.gz", sample=SAMPLES),
                expand("workpanel/RPM/{sample}.probe.rpm_rate.bed.gz.tbi", sample=SAMPLES),
		config['outputdir']

#rule process_input_file:
#	input:
#		"panel.samples"
#	output:
#		directory(".workpanel/")
#	shell:
#		'mkdir .workpanel; cat {input} | gargs --sep="\t" "ln -s {{3}} .workpanel/{{0}}.bam"'

rule mosdepth:
	input:
		"workpanel/{sample}.bam"
	output:
		"workpanel/Mosdepth/{sample}.per-base.bed.gz",
		"workpanel/Mosdepth/{sample}.per-base.bed.gz.tbi"
	log:
		"logs/mosdepth.{sample}.log"
	shell:
		"""
		mkdir -p workpanel/Mosdepth
		mosdepth workpanel/Mosdepth/{wildcards.sample} {input}
		tabix -p bed workpanel/Mosdepth/{wildcards.sample}.per-base.bed.gz
		"""

rule count_reads:
        input:
                "workpanel/{sample}.bam"
        output:
                "workpanel/ReadCounts/{sample}.num_reads.txt"
        log:
                "logs/mosdepth.{sample}.log"
        shell:
                """
		samtools view -c -F 260 {input} > {output}
                """

rule get_total_read_counts:
	input:
		expand("workpanel/ReadCounts/{sample}.num_reads.txt", sample=SAMPLES)
	output:
		"workpanel/TotalReads/total_read.txt"
	shell:
		"""
		cat {input} > workpanel/TotalReads/total_read.txt
		"""

rule gzip_probes:
	input:
		probes = config['probes']
	output:
		"workpanel/Probes/probes.sorted.bed.gz",
		"workpanel/Probes/probes.sorted.bed.gz.tbi"
	shell:
		"""
		mkdir -p workpanel/Probes/
		bedtools sort -i {input.probes} > workpanel/Probes/probes.sorted.bed
		bgzip workpanel/Probes/probes.sorted.bed
		tabix workpanel/Probes/probes.sorted.bed.gz -p bed
		"""

rule get_probe_reads_per_million:
	input:
		per_base_bed_gz="workpanel/Mosdepth/{sample}.per-base.bed.gz",
		total_reads="workpanel/TotalReads/total_read.txt",
		probes_gz="workpanel/Probes/probes.sorted.bed.gz"
	output:
		"workpanel/RPM/{sample}.probe.rpm_rate.bed.gz",
		"workpanel/RPM/{sample}.probe.rpm_rate.bed.gz.tbi"
	shell:
		"""
		python bin/get_rpm_rates.py \
		-m {input.per_base_bed_gz} \
		--regions_file {input.probes_gz} \
		--num_reads {input.total_reads} \
		| bgzip -c > workpanel/RPM/{wildcards.sample}.probe.rpm_rate.bed.gz
		tabix -p bed workpanel/RPM/{wildcards.sample}.probe.rpm_rate.bed.gz
		"""

rule create_panel_db:
	input:
		rpm_gz=expand("workpanel/RPM/{sample}.probe.rpm_rate.bed.gz", sample=SAMPLES),
		rpm_tbi=expand("workpanel/RPM/{sample}.probe.rpm_rate.bed.gz.tbi", sample=SAMPLES),
		all_calls=config['all_calls'],
		sample_list=SAMPLES_FILE
	output:
		directory(config['outputdir'])
	shell:
		"""
		mkdir -p {output}/RPM
		mkdir -p {output}/Calls
		cp {input.rpm_gz} {output}/RPM
		cp {input.rpm_tbi} {output}/RPM
		while read p; do
			cp "$p" {output}/Calls
		done <{input.all_calls}
		cp {input.sample_list} {output}
		"""
		












